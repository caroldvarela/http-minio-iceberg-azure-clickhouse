{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlt[clickhouse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a1b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "import pyarrow as pa\n",
    "import dlt\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.fs as fs\n",
    "from dlt.sources.filesystem import filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2488e",
   "metadata": {},
   "source": [
    "## **Connect to the Nessie catalog**\n",
    "\n",
    "Re-establish the connection to the **Nessie REST catalog**.  \n",
    "This allows us to read metadata and schema information from the Iceberg tables  \n",
    "that were created and loaded in the previous steps.\n",
    "\n",
    "We verify the connection by listing all available namespaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespaces: [('taxis-project',)]\n"
     ]
    }
   ],
   "source": [
    "# Configure the connection to the Nessie REST catalog\n",
    "catalog = load_catalog(\n",
    "    \"nessie\",\n",
    "    **{\n",
    "        \"uri\": \"http://nessie:19120/iceberg/main/\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Verify the connection by listing the namespaces\n",
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Namespaces:\", namespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2cb027",
   "metadata": {},
   "source": [
    "## **Extract Iceberg data and load it into ClickHouse**\n",
    "\n",
    "This notebook executes the **fourth and final stage** of the project pipeline:  \n",
    "**migrating the Iceberg data stored in MinIO into a ClickHouse database** for analytical querying.\n",
    "\n",
    "**Process overview:**\n",
    "\n",
    "1. **Connect to MinIO**  \n",
    "   - Configure an S3-compatible connection to MinIO using access credentials.\n",
    "\n",
    "2. **Define the DLT resource (`iceberg_df`)**  \n",
    "   - Load the Iceberg table `taxis-project.taxis` from the Nessie catalog.  \n",
    "   - Scan the table and convert it into an Arrow Table.  \n",
    "   - Yield the data in batches, allowing efficient ingestion into ClickHouse.\n",
    "\n",
    "3. **Create and configure the pipeline**  \n",
    "   - Name: `clickhouse_pipeline`  \n",
    "   - Destination: `clickhouse`  \n",
    "   - Dataset name: `taxis_project`.\n",
    "\n",
    "4. **Execute the pipeline**  \n",
    "   - Runs the DLT job that transfers all Iceberg table data into ClickHouse.  \n",
    "   - The parameter `write_disposition=\"replace\"` ensures a full table refresh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 14:59:20,618|[WARNING]|1153|138890886543168|dlt|type_mapping.py|to_db_datetime_type:58|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'taxis'.\n",
      "2025-10-21 14:59:20,618|[WARNING]|1153|138890886543168|dlt|type_mapping.py|to_db_datetime_type:58|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'taxis'.\n",
      "2025-10-21 14:59:20,662|[WARNING]|1153|138890886543168|dlt|type_mapping.py|to_db_datetime_type:58|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'taxis'.\n",
      "2025-10-21 14:59:20,663|[WARNING]|1153|138890886543168|dlt|type_mapping.py|to_db_datetime_type:58|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'taxis'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline clickhouse_pipeline load step completed in 2.91 seconds\n",
      "1 load package(s) were loaded to destination clickhouse and into dataset taxis_project\n",
      "The clickhouse destination used clickhouse://default:***@clickhouse:9000/default location to store data\n",
      "Load package 1761058758.772736 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "s3 = fs.S3FileSystem(\n",
    "    endpoint_override=\"http://minio:9000\",  # inside Docker: use \"minio:9000\", from local: \"localhost:9000\"\n",
    "    access_key=\"admin\",\n",
    "    secret_key=\"password\",\n",
    "    region=\"us-east-1\"\n",
    ")\n",
    "\n",
    "iceberg_table_path = \"my-bucket/taxis-project/taxis\"\n",
    "\n",
    "@dlt.resource(table_name=\"taxis\")\n",
    "def iceberg_df():\n",
    "    # Load the Iceberg table from the Nessie catalog\n",
    "    taxis = catalog.load_table(\"taxis-project.taxis\")\n",
    "    \n",
    "    # Run the table scan and get an Arrow Table\n",
    "    arrow_table = taxis.scan().to_arrow()\n",
    "    \n",
    "    # Iterate through Arrow batches\n",
    "    for batch in arrow_table.to_batches():\n",
    "        yield batch\n",
    "\n",
    "\n",
    "# Initialize the DLT pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "  pipeline_name='clickhouse_pipeline',\n",
    "  destination='clickhouse',\n",
    "  dataset_name='taxis_project'\n",
    ")\n",
    "\n",
    "# Define the source (filesystem connector)\n",
    "source = filesystem()\n",
    "\n",
    "# Run the pipeline\n",
    "load_info = pipeline.run(\n",
    "    iceberg_df,             # use the Iceberg table resource\n",
    "    loader_file_format=\"parquet\",\n",
    "    write_disposition=\"replace\"\n",
    ")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fdd26",
   "metadata": {},
   "source": [
    "The pipeline successfully loaded the Iceberg data into ClickHouse in approximately **2.9 seconds**.\n",
    "\n",
    "- Destination: ClickHouse database (`taxis_project` dataset).  \n",
    "- Loader format: Parquet.  \n",
    "- Disposition: Replace (existing table overwritten).  \n",
    "- No failed jobs detected.\n",
    "\n",
    "Once this step is verified with record counts and metadata queries,\n",
    "the full end-to-end data pipeline is successfully implemented.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
